#!/bin/sh
#SBATCH -J solve_motorbike
#SBATCH -o logs/solve_motorbike.o%J
#SBATCH -e logs/solve_motorbike.e%J
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=36
#SBATCH --ntasks-per-core=1

source /nfs/cluster/intel/oneapi/compiler/latest/env/vars.sh
source /nfs/cluster/intel/oneapi/mpi/latest/env/vars.sh
source /nfs/cluster/app/impi/OpenFOAM-v2206/etc/bashrc

NPROCS=${SLURM_NTASKS}
export HOSTFILE="./hostfile"
export MPI=$(which mpirun)
export MPI_BASE_OPTIONS="-np $NPROCS -hostfile $HOSTFILE -genv I_MPI_DEBUG=5"
export MPI_RoCEv2_OPTIONS="-iface ens800f0 -genv UCX_TLS=rc,self,sm -genv UCX_NET_DEVICES=mlx5_2:1 -genv I_MPI_FABRICS=shm:ofi"
export MPI_Pinning_OPTIONS=""
export MPI_OPTIONS="${MPI_BASE_OPTIONS} ${MPI_RoCEv2_OPTIONS} ${MPI_Pinning_OPTIONS}"

cd ${SLURM_SUBMIT_DIR}

scontrol show hostname $SLURM_JOB_NODELIST | sed 's/$/:36/' > ./hostfile

# Source tutorial run functions
. $WM_PROJECT_DIR/bin/tools/RunFunctions

# NOTE: To launch without the runParallel, do the following:
#
#           mpirun -np $NPROCS simpleFoam -parallel
#
#runParallel simpleFoam
echo "Running simpleFoam on `pwd`"
${MPI} ${MPI_OPTIONS} simpleFoam -parallel  >& log.simpleFoam

# ----------------------------------------------------------------- end-of-file
